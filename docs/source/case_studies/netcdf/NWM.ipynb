{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1aec28e",
   "metadata": {},
   "source": [
    "# National Water Model - Short Range Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad7e55",
   "metadata": {},
   "source": [
    "## Dataset description and why itâ€™s a good kerchunk candidate\n",
    "The National Water Model dataset is a produced by the National Oceanic and Atmospheric Administations (NOAA's) Office of Water Prediction. It is a forecast model of water resources, providing multiple variables across the continental United States (CONUS). \n",
    "This dataset is available via the Registry of Open Data on AWS as a collection of netCDF files that do not require any login authentication. Using `kerchunk`, we will demonstrate how to build a kerchunk index so that this dataset can be read as if it were a ARCO dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Imports\n",
    "from kerchunk.hdf import SingleHdf5ToZarr\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "import fsspec_reference_maker\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import os\n",
    "import ujson\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9fbd77",
   "metadata": {},
   "source": [
    "## Create input file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdeafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fsspec filesystem for AWS s3.\n",
    "fs = fsspec.filesystem('s3', anon=True, skip_instance_cache=True)\n",
    "# Use fsspec and glob to retrieve a list of all netCDF files to be used in the kerchunk index generation.\n",
    "flist = fs.glob(f'noaa-nwm-pds/nwm.*/short_range/nwm.*.short_range.channel_rt.f001.conus.nc')\n",
    "\n",
    "# Join the \"best time series\" from past forecasts with the latest forecast\n",
    "# Remove the first day of data since this is a rolling collection and \n",
    "# we don't want to be trying to access files that soon will be removed. \n",
    "# & Use all the files from the last forecast cycle\n",
    "\n",
    "last_dir = f'{os.path.dirname(flist[-1])}'\n",
    "last_file = os.path.basename(flist[-1]).split('.')\n",
    "last_files = fs.glob(f'{last_dir}/{last_file[0]}.{last_file[1]}.{last_file[2]}.channel_rt.*.conus.nc')\n",
    "\n",
    "# Skip the first of the last_files since it's a duplicate\n",
    "flist.extend(last_files[1:])\n",
    "\n",
    "# We need to include the \"s3://\" prefix to the list of files\n",
    "# so that fsspec will recognize that these JSON files are on S3. There is no \"storage_\n",
    "urls = [\"s3://\" + f for f in flist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963edaee",
   "metadata": {},
   "source": [
    "## Iterate through filelist and create kerchunk indicies as .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798df6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsspec.open args\n",
    "so = dict(mode='rb', anon=True, default_fill_cache=False, default_cache_type='first')\n",
    "output_dir = './NWM_dir'\n",
    "\n",
    "# Use kerchunk's SingleHdf5ToZarr to transform netcdf to kerchunk index.\n",
    "def gen_json(u, output_dir: str):\n",
    "    with fs.open(u, **so) as infile:\n",
    "        h5chunks = SingleHdf5ToZarr(infile, u, inline_threshold=300)\n",
    "        p = u.split('/')\n",
    "        date = p[3]\n",
    "        fname = p[5]\n",
    "        outf = f'{output_dir}/{date}.{fname}.json'\n",
    "        with open(outf, 'wb') as f:\n",
    "            f.write(ujson.dumps(h5chunks.translate()).encode());\n",
    "        return outf\n",
    "\n",
    "# Iterate through filelist to generate kerchunked files. Good use for dask\n",
    "output_files = []\n",
    "for fil in tqdm(urls):\n",
    "    outf = gen_json(fil, output_dir)\n",
    "    output_files.append(outf)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758c452",
   "metadata": {},
   "source": [
    "## Combine .json kerchunk reference files and write a combined kerchunk index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f37ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine single kerchunk output reference files into a multi file kerchunk dataset\n",
    "mzz = MultiZarrToZarr(output_files, concat_dims=['time'])\n",
    "d = mzz.translate()\n",
    "\n",
    "# Write kerchunk .json record\n",
    "output_fname = 'NWM.json'\n",
    "with open(f'{output_fname}', 'wb') as f:\n",
    "    f.write(ujson.dumps(d).encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e27f3",
   "metadata": {},
   "source": [
    "## Load kerchunked dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a fsspec reference filesystem from the kerchunk output\n",
    "fs = fsspec.filesystem(\"reference\", fo=output_fname)\n",
    "m = fs.get_mapper(\"\")\n",
    "ds = xr.open_zarr(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
