{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa35905",
   "metadata": {},
   "source": [
    "# GLOBAL SEASONAL SENTINEL-1 INTERFEROMETRIC COHERENCE AND BACKSCATTER DATA SET\n",
    "\n",
    "See http://sentinel-1-global-coherence-earthbigdata.s3-website-us-west-2.amazonaws.com/ for a description of the data description, format and layout. It is made of millions of geoTIFF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e4b7e-21fa-46cd-93cd-e8db56d8a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import geoviews as gv\n",
    "import imagecodecs.numcodecs\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import panel as pn\n",
    "import param\n",
    "import intake\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "imagecodecs.numcodecs.register_codecs()  # register the TIFF codec\n",
    "pn.extension()  # viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13456f4-35ce-4254-a172-ca26b320661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = intake.open_data(\"https://github.com/fsspec/kerchunk/raw/main/\"\n",
    "                           \"examples/intake_catalog.yml\")['sentinel_seasonal'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.nbytes / 2**40 # effective in-memory size, in TB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e62f71",
   "metadata": {},
   "source": [
    "### Dataspace Browser\n",
    "\n",
    "Much of the dimension space is empty, contains no data file. These areas would return a bunch of NaNs if we tried to extract the data. To be able to explore, we create a view of the whole dataset, showing where data files do exist.\n",
    "We do this very much downsampled, because the process is quite slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dabb1-06a9-4475-a1fa-07ecb1612e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb4665-3c60-4089-87ce-31b21d9fbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "das = {}\n",
    "new_coords = {}\n",
    "for var in dataset.data_vars:\n",
    "    newc = {k:v.values for k,v in dataset[var].coords.items()}\n",
    "    newc['latitude'] = np.arange(89.5, -90.5, -STEP)\n",
    "    newc['longitude'] = np.arange(-179.5, 180.5, STEP)\n",
    "    empty_da = xr.DataArray(data=np.nan, dims=list(newc), coords=newc)\n",
    "    das[var] = empty_da\n",
    "    new_coords[var] = newc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba5054-326c-4302-89cd-ce0b8b17b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ds = xr.Dataset(das)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c6622-aad9-4b2f-ba87-67fadf5d2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "zkeys = set(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d804432-f57a-4008-a2ae-6bdd619f9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_idx(array, value):\n",
    "    if array[1] > array[0]:\n",
    "        idx = np.searchsorted(array, value, side=\"left\")\n",
    "        if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "            idx = idx-1\n",
    "    else:\n",
    "        idx = array.size - np.searchsorted(array[::-1], value, side=\"right\")\n",
    "        # idx = np.searchsorted(array, value, side=\"left\", sorter=np.argsort(array))\n",
    "        if idx > 0 and (idx == len(array) or math.fabs(value - array[idx]) < math.fabs(value - array[idx+1])):\n",
    "            idx = idx-1\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf0688-3e36-4dc8-84f7-1605917678cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zarr_key(variable: xr.DataArray, coords: dict, chunks: dict, indexes: dict) -> str:\n",
    "    chunk = []\n",
    "    for i, dim in enumerate(variable.dims):\n",
    "        vals = indexes[dim]\n",
    "        if vals.dtype == \"O\":\n",
    "            chunk.append(list(vals).index(coords[dim]) // chunks[dim])\n",
    "        else:\n",
    "            chunk.append(find_nearest_idx(vals.values, coords[dim]) // chunks[dim])\n",
    "    return variable.name + \"/\" + \".\".join(str(ch) for ch in chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b803ac-c3fb-4e09-814e-5f6ee357af3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "chunks = {\"latitude\": 1200, \"longitude\": 1200}\n",
    "\n",
    "for var in mask_ds.data_vars:\n",
    "    print(f'Processing {var}...')\n",
    "    chunks = {dim: chunks.get(dim, 1) for i, dim in enumerate(dataset[var].dims)}\n",
    "    # chunks = {dim:dataset[var].chunks[i][0] for i, dim in enumerate(dataset[var].dims)}\n",
    "    indexes = {dim: dataset[var].indexes[dim] for dim in dataset[var].dims}\n",
    "    total = mask_ds[var].size\n",
    "    mask = np.full(total, np.nan, dtype=np.float32)\n",
    "    for i, coords in enumerate(itertools.product(*(new_coords[var].values()))):\n",
    "        coords = dict(zip(new_coords[var].keys(), coords))\n",
    "        zkey = zarr_key(dataset[var], coords, chunks, indexes)\n",
    "        mask[i] = zkey in zkeys\n",
    "    mask = mask.reshape(mask_ds[var].shape)\n",
    "    mask = np.where(mask == 0, np.nan, 1)\n",
    "    mask_ds[var].values = mask\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce996c62",
   "metadata": {},
   "source": [
    "### Viz tool\n",
    "\n",
    "We use a custom viz tool to be able to navigate the data space. As coded here, this will open in a separate browser tab. We may generalise this tool for other datasets in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7a7aa-c8d3-422c-a0f4-f4ff85d43f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.config.image_rtol = 0.01\n",
    "\n",
    "class ZarrExplorer(param.Parameterized):\n",
    "    local_map_extent = param.Number(default=0.2)\n",
    "    variable = param.Selector(doc='Dataset Variable', default='COH', objects=list(mask_ds.data_vars))\n",
    "    stream_tap_global = param.ClassSelector(hv.streams.SingleTap, hv.streams.SingleTap(x=-40, y=70), precedence=-1)\n",
    "    update_localmap = param.Action(lambda x: x.param.trigger('update_localmap'), label='Click to load data after panning/zooming')\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.global_map()\n",
    "        self.lm = pn.pane.HoloViews(None, linked_axes=False)\n",
    "        self.stream_rng = hv.streams.RangeXY()\n",
    "        self.x_range, self.y_range = None, None\n",
    "        self.update_local_map_after_map_click()\n",
    "\n",
    "    @param.depends('variable')\n",
    "    def global_map(self):\n",
    "        ds = hv.Dataset(mask_ds[self.variable])\n",
    "        self.img_dm = ds.to(gv.QuadMesh, kdims=['longitude', 'latitude'], dynamic=True).opts()\n",
    "        self.img_dm.cache_size = 1  # No cache so that last_key returns the current widgets state\n",
    "        overlay = self.img_dm * gv.feature.coastline\n",
    "        self.stream_tap_global.source = self.img_dm  # Attache the tap stream to this map\n",
    "        overlay = overlay * self.withregion()\n",
    "        return pn.panel(overlay.opts(width=600, height=500), widget_location='left')\n",
    "\n",
    "    def withregion(self):\n",
    "        def make_point(x, y):\n",
    "            return gv.Points([(x, y)]).opts(color='red', marker='+', size=20)\n",
    "        return hv.DynamicMap(make_point, streams=dict(x=self.stream_tap_global.param.x, y=self.stream_tap_global.param.y))\n",
    "\n",
    "    @param.depends('stream_tap_global.x', 'stream_tap_global.y', watch=True)\n",
    "    def update_local_map_after_map_click(self):\n",
    "        x, y = self.stream_tap_global.x, self.stream_tap_global.y\n",
    "        half_lme = self.local_map_extent / 2\n",
    "        self.x_range = (x-half_lme, x+half_lme)\n",
    "        self.y_range = (y+half_lme, y-half_lme)  # The dataset has reversed longitude\n",
    "\n",
    "    @param.depends('update_localmap', watch=True)\n",
    "    def update_local_map_after_refresh(self):\n",
    "        y0, y1 = self.stream_rng.y_range\n",
    "        self.x_range = self.stream_rng.x_range\n",
    "        self.y_range = (y1, y0)  # The dataset has reversed longitude\n",
    "    \n",
    "    @param.depends('update_local_map_after_map_click', 'update_local_map_after_refresh')\n",
    "    def local_map(self):\n",
    "        if self.img_dm.last_key:\n",
    "            state = {kdim.name: val for kdim, val in zip(self.img_dm.kdims, self.img_dm.last_key)}\n",
    "        else:\n",
    "            state = {kdim.name: kdim.values[0] for kdim in self.img_dm.kdims}\n",
    "        dssub = dataset[self.variable].sel(latitude=slice(*self.y_range), longitude=slice(*self.x_range), **state)\n",
    "        title = f'{self.variable} @' + ', '.join(f'{dim}: {val}' for dim, val in state.items())\n",
    "        img = dssub.hvplot.image(\n",
    "            x=\"longitude\", y=\"latitude\",\n",
    "            cmap='spectral_r', frame_width=400, aspect='equal', \n",
    "            rasterize=True,\n",
    "            title=title,\n",
    "            shared_axes=False,\n",
    "        )\n",
    "        self.stream_rng.source = img\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3399751-711b-4f85-b544-17376f614f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ze = ZarrExplorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fa960-c080-4459-b9cf-0326ff1a7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pn.Column(\n",
    "    pn.Param(ze.param.variable, width=150),\n",
    "    pn.Row(\n",
    "        ze.global_map,\n",
    "        pn.Column(\n",
    "            pn.panel(ze.local_map, loading_indicator=True),\n",
    "            ze.param.update_localmap\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "app.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f6d2c-cea7-4230-b6fa-47fdc1e92fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
